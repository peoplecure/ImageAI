{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating anchor boxes for training images and annotation...\n",
      "not well-formed (invalid token): line 1, column 0\n",
      "Ignore this bad annotation: puzzle/train/annotations/.DS_Store\n",
      "Average IOU for 9 anchors: 1.00\n",
      "Anchor Boxes generated.\n",
      "Detection configuration saved in  puzzle/json/detection_config.json\n",
      "not well-formed (invalid token): line 1, column 0\n",
      "Ignore this bad annotation: puzzle/validation/annotations/.DS_Store\n",
      "Evaluating over 1 samples taken from puzzle/validation\n",
      "Training over 2 samples  given at puzzle/train\n",
      "Training on: \t['dog']\n",
      "Training with Batch Size:  2\n",
      "Number of Training Samples:  2\n",
      "Number of Validation Samples:  1\n",
      "Number of Experiments:  10\n",
      "Training with transfer learning from pretrained Model\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer YoloLayer has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/10\n",
      "8/8 [==============================] - 95s 12s/step - loss: 125.8287 - yolo_layer_14_loss: 17.4822 - yolo_layer_15_loss: 31.2047 - yolo_layer_16_loss: 65.5686 - val_loss: 76.4468 - val_yolo_layer_14_loss: 11.3788 - val_yolo_layer_15_loss: 17.7446 - val_yolo_layer_16_loss: 35.7502\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 76s 10s/step - loss: 103.3881 - yolo_layer_14_loss: 14.5825 - yolo_layer_15_loss: 24.4141 - yolo_layer_16_loss: 52.8182 - val_loss: 76.7965 - val_yolo_layer_14_loss: 11.4136 - val_yolo_layer_15_loss: 17.6949 - val_yolo_layer_16_loss: 36.1146\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 83s 11s/step - loss: 95.6522 - yolo_layer_14_loss: 13.9541 - yolo_layer_15_loss: 21.6385 - yolo_layer_16_loss: 48.4861 - val_loss: 74.0795 - val_yolo_layer_14_loss: 11.0835 - val_yolo_layer_15_loss: 16.5187 - val_yolo_layer_16_loss: 34.9036\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 63s 8s/step - loss: 76.3559 - yolo_layer_14_loss: 11.3350 - yolo_layer_15_loss: 15.9079 - yolo_layer_16_loss: 37.5392 - val_loss: 77.7710 - val_yolo_layer_14_loss: 11.7775 - val_yolo_layer_15_loss: 17.3032 - val_yolo_layer_16_loss: 37.1162\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 79s 10s/step - loss: 72.5036 - yolo_layer_14_loss: 11.6172 - yolo_layer_15_loss: 13.4150 - yolo_layer_16_loss: 35.8972 - val_loss: 78.3968 - val_yolo_layer_14_loss: 11.6145 - val_yolo_layer_15_loss: 16.9267 - val_yolo_layer_16_loss: 38.2811\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 78s 10s/step - loss: 59.0854 - yolo_layer_14_loss: 9.8983 - yolo_layer_15_loss: 10.0878 - yolo_layer_16_loss: 27.5247 - val_loss: 75.6457 - val_yolo_layer_14_loss: 10.7870 - val_yolo_layer_15_loss: 16.2582 - val_yolo_layer_16_loss: 37.0256\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 73s 9s/step - loss: 55.5776 - yolo_layer_14_loss: 9.9199 - yolo_layer_15_loss: 9.6992 - yolo_layer_16_loss: 24.3835 - val_loss: 67.8322 - val_yolo_layer_14_loss: 10.6882 - val_yolo_layer_15_loss: 12.7567 - val_yolo_layer_16_loss: 32.8120\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 68s 9s/step - loss: 48.2451 - yolo_layer_14_loss: 8.8120 - yolo_layer_15_loss: 7.8592 - yolo_layer_16_loss: 19.9985 - val_loss: 58.0971 - val_yolo_layer_14_loss: 8.9617 - val_yolo_layer_15_loss: 9.7427 - val_yolo_layer_16_loss: 27.8169\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 75s 9s/step - loss: 48.8981 - yolo_layer_14_loss: 10.1527 - yolo_layer_15_loss: 7.7481 - yolo_layer_16_loss: 19.4216 - val_loss: 60.2852 - val_yolo_layer_14_loss: 8.9548 - val_yolo_layer_15_loss: 8.6832 - val_yolo_layer_16_loss: 31.0711\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 72s 9s/step - loss: 43.2122 - yolo_layer_14_loss: 9.8002 - yolo_layer_15_loss: 5.8909 - yolo_layer_16_loss: 15.9449 - val_loss: 55.6469 - val_yolo_layer_14_loss: 8.4178 - val_yolo_layer_15_loss: 7.4726 - val_yolo_layer_16_loss: 28.1802\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"puzzle\")\n",
    "trainer.setTrainConfig(object_names_array=[\"dog\"], batch_size=2, num_experiments=10, train_from_pretrained_model=\"pretrained-yolov3.h5\")\n",
    "# In the above,when training for detecting multiple objects,\n",
    "#set object_names_array=[\"object1\", \"object2\", \"object3\",...\"objectz\"]\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Model evaluation....\n",
      "Evaluating over 1 samples taken from puzzle/validation\n",
      "Training over 2 samples  given at puzzle/train\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model File:  ./puzzle/models/detection_model-ex-009--loss-0047.906.h5 \n",
      "\n",
      "Evaluation samples:  1\n",
      "Using IoU:  0.5\n",
      "Using Object Threshold:  0.3\n",
      "Using Non-Maximum Suppression:  0.5\n",
      "dog: 0.0002\n",
      "mAP: 0.0002\n",
      "===============================\n"
     ]
    }
   ],
   "source": [
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "trainer.setDataDirectory(data_directory=\"puzzle\")\n",
    "metrics = trainer.evaluateModel(model_path=\"./puzzle/models/detection_model-ex-009--loss-0047.906.h5\", json_path=\"./puzzle/json/detection_config.json\", iou_threshold=0.5, object_threshold=0.3, nms_threshold=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
